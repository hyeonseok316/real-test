{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\남현석\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] 지정된 모듈을 찾을 수 없습니다. Error loading \"C:\\Users\\남현석\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobjRemove\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObjectRemove\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepFill\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
      "File \u001b[1;32mc:\\Users\\남현석\\Desktop\\남현석\\영재고\\졸업연구\\src\\objRemove.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT\u001b[39;00m  \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_image\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mObjectRemove\u001b[39;00m():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] 지정된 모듈을 찾을 수 없습니다. Error loading \"C:\\Users\\남현석\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from objRemove import ObjectRemove\n",
    "from models.deepFill import Generator\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengthFinger(land, wid, hei):\n",
    "    return ((land[2].x*wid - land[1].x*wid)**2 + (land[2].y*hei - land[1].y*hei)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myObjRemove(image_file, minx, miny, maxx, maxy):\n",
    "  ######################################################\n",
    "  #creating Mask-RCNN model and load pretrained weights#\n",
    "  ######################################################\n",
    "  for f in os.listdir('/content/drive/MyDrive/Colab Notebooks/졸업연구/src/models'):\n",
    "      if f.endswith('.pth'):\n",
    "          deepfill_weights_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/졸업연구/src/models', f)\n",
    "  print(\"Creating rcnn model\")\n",
    "  weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "  transforms = weights.transforms()\n",
    "  rcnn = maskrcnn_resnet50_fpn(weights=weights, progress=False)\n",
    "  rcnn = rcnn.eval()\n",
    "\n",
    "  #########################\n",
    "  #create inaptining model#\n",
    "  #########################\n",
    "  print('Creating deepfil model')\n",
    "  deepfill = Generator(checkpoint=deepfill_weights_path, return_flow=True)\n",
    "  ######################\n",
    "  #create ObjectRemoval#\n",
    "  ######################\n",
    "  model = ObjectRemove(segmentModel=rcnn,\n",
    "                          rcnn_transforms=transforms,\n",
    "                          inpaintModel=deepfill,\n",
    "                          image_file=image_file,\n",
    "                          minx=minx,\n",
    "                          miny=miny,\n",
    "                          maxx=maxx,\n",
    "                          maxy=maxy)\n",
    "\n",
    "  # model.minx = minx\n",
    "  # model.miny = miny\n",
    "  # model.maxx = maxx\n",
    "  # model.maxy = maxy\n",
    "\n",
    "\n",
    "  #####\n",
    "  #run#\n",
    "  #####\n",
    "  output = model.run()\n",
    "\n",
    "  #################\n",
    "  #display results#\n",
    "  #################\n",
    "  img = cv2.cvtColor(model.image_orig[0].permute(1,2,0).numpy(),cv2.COLOR_RGB2BGR)\n",
    "  boxed = cv2.rectangle(img, (model.box[0], model.box[1]),(model.box[2], model.box[3]), (0,255,0),2)\n",
    "  boxed = cv2.cvtColor(boxed,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # fig,axs = plt.subplots(1,3,layout='constrained')\n",
    "  # axs[0].imshow(boxed)\n",
    "  # axs[0].set_title('Original Image Bounding Box')\n",
    "  # axs[1].imshow(model.image_masked.permute(1,2,0).detach().numpy())\n",
    "  # axs[1].set_title('Masked Image')\n",
    "  # axs[2].imshow(output)\n",
    "  # axs[2].set_title('Inpainted Image')\n",
    "  # plt.show()\n",
    "  # cv2_imshow(output)\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/hand0.png\n",
      "../img/hand1.png\n",
      "../img/hand2.png\n",
      "[{'minx': [-7, 350], 'miny': [-24, 58], 'maxx': [388, 801], 'maxy': [534, 561]}, {'minx': [147], 'miny': [237], 'maxx': [368], 'maxy': [582]}, {'minx': [22], 'miny': [67], 'maxx': [250], 'maxy': [362]}]\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일의 경우을 사용하세요.:\n",
    "# IMAGE_FILES = [\"/content/drive/MyDrive/Colab Notebooks/졸업연구/img/test/test\" + str(i) + \".jpg\" for i in range(7)]\n",
    "directory_path = '/content/drive/MyDrive/Colab Notebooks/졸업연구/img/test/'\n",
    "IMAGE_FILES = os.listdir(directory_path)\n",
    "ranges = []\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        # 이미지를 읽어 들이고, 보기 편하게 이미지를 좌우 반전합니다.\n",
    "        # print(file)\n",
    "        image = cv2.flip(cv2.imread(directory_path + file), 1)\n",
    "        # 작업 전에 BGR 이미지를 RGB로 변환합니다.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # 손으로 프린트하고 이미지에 손 랜드마크를 그립니다.\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        range_dict = {\"minx\":[], \"miny\":[], \"maxx\":[], \"maxy\":[]}\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "            len_fing = lengthFinger(hand_landmarks.landmark, image_width, image_height)\n",
    "            minx, miny, maxx, maxy = image_width, image_height, 0, 0\n",
    "\n",
    "            for land in hand_landmarks.landmark:\n",
    "                if minx > land.x*image_width: minx = land.x*image_width\n",
    "                if maxx < land.x*image_width: maxx = land.x*image_width\n",
    "                if miny > land.y*image_height: miny = land.y*image_height\n",
    "                if maxy < land.y*image_height: maxy = land.y*image_height\n",
    "                \n",
    "            minx -= len_fing/2\n",
    "            miny -= len_fing/2\n",
    "            maxx += len_fing/2\n",
    "            maxy += len_fing/2\n",
    "            minx, miny, maxx, maxy = int(minx), int(miny), int(maxx), int(maxy)\n",
    "            # cv2.rectangle(annotated_image, (minx, miny), (maxx, maxy), (0, 0, 255), 3)\n",
    "            \n",
    "            range_dict['minx'].append(minx)\n",
    "            range_dict['miny'].append(miny)\n",
    "            range_dict['maxx'].append(maxx)\n",
    "            range_dict['maxy'].append(maxy)\n",
    "        \n",
    "        for i in range(len(range_dict['minx'])):\n",
    "            annotated_image = myObjRemove(annotated_image,\n",
    "                                          range_dict['minx'][i],\n",
    "                                          range_dict['miny'][i],\n",
    "                                          range_dict['maxx'][i],\n",
    "                                          range_dict['maxy'][i])\n",
    "        \n",
    "        ranges.append(range_dict)\n",
    "\n",
    "        # cv2.imwrite('../img/testbox/testbox' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "        # plt.imshow(cv2.flip(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB), 1))\n",
    "        print(\"\\n\\n\"+file+\" is done\")\n",
    "        cv2_imshow(cv2.flip(annotated_image, 1))\n",
    "\n",
    "print(ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/test/test0.jpg\n",
      "../img/test/test1.jpg\n",
      "../img/test/test2.jpg\n",
      "../img/test/test3.jpg\n",
      "../img/test/test4.jpg\n",
      "../img/test/test5.jpg\n",
      "../img/test/test6.jpg\n",
      "[{'minx': [412], 'miny': [327], 'maxx': [626], 'maxy': [615]}, {'minx': [353, 520], 'miny': [508, 431], 'maxx': [447, 665], 'maxy': [600, 549]}, {'minx': [425], 'miny': [761], 'maxx': [513], 'maxy': [823]}, {'minx': [908, 127], 'miny': [353, 315], 'maxx': [1002, 221], 'maxy': [465, 436]}, {'minx': [689, 586], 'miny': [885, 708], 'maxx': [877, 711], 'maxy': [1006, 843]}, {'minx': [681, 203], 'miny': [979, 920], 'maxx': [764, 302], 'maxy': [1089, 1050]}, {'minx': [105, 695], 'miny': [896, 729], 'maxx': [279, 850], 'maxy': [1106, 900]}]\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일의 경우을 사용하세요.:\n",
    "IMAGE_FILES = [\"../img/test/test\" + str(i) + \".jpg\" for i in range(7)]\n",
    "ranges = []\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    \n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        # 이미지를 읽어 들이고, 보기 편하게 이미지를 좌우 반전합니다.\n",
    "        print(file)\n",
    "        image = cv2.flip(cv2.imread(file), 1)\n",
    "        # 작업 전에 BGR 이미지를 RGB로 변환합니다.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # 손으로 프린트하고 이미지에 손 랜드마크를 그립니다.\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        range_dict = {\"minx\":[], \"miny\":[], \"maxx\":[], \"maxy\":[]}\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "            len_fing = lengthFinger(hand_landmarks.landmark, image_width, image_height)\n",
    "            minx, miny, maxx, maxy = image_width, image_height, 0, 0\n",
    "            \n",
    "            for land in hand_landmarks.landmark:\n",
    "                if minx > land.x*image_width: minx = land.x*image_width\n",
    "                if maxx < land.x*image_width: maxx = land.x*image_width\n",
    "                if miny > land.y*image_height: miny = land.y*image_height\n",
    "                if maxy < land.y*image_height: maxy = land.y*image_height\n",
    "                \n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "            minx -= len_fing/2\n",
    "            miny -= len_fing/2\n",
    "            maxx += len_fing/2\n",
    "            maxy += len_fing/2\n",
    "            minx, miny, maxx, maxy = int(minx), int(miny), int(maxx), int(maxy)\n",
    "            cv2.rectangle(annotated_image, (minx, miny), (maxx, maxy), (0, 0, 255), 1)\n",
    "            \n",
    "            range_dict['minx'].append(minx)\n",
    "            range_dict['miny'].append(miny)\n",
    "            range_dict['maxx'].append(maxx)\n",
    "            range_dict['maxy'].append(maxy)\n",
    "        ranges.append(range_dict)\n",
    "            \n",
    "        cv2.imwrite('../img/testbox/testbox' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "\n",
    "print(ranges)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
